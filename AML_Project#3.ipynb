{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Detection of Toxic Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download FastText embeddings\n",
    "### Step 2: Using function get_embeddings() create embeddings index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "id                                                                           \n",
      "00001cee341fdb12     -1            -1       -1      -1      -1             -1\n",
      "0000247867823ef7     -1            -1       -1      -1      -1             -1\n",
      "00013b17ad220c46     -1            -1       -1      -1      -1             -1\n",
      "00017563c3f7919a     -1            -1       -1      -1      -1             -1\n",
      "00017695ad8997eb     -1            -1       -1      -1      -1             -1\n",
      "0.41770912224804785 % of test is labelled\n",
      "(223549, 7) (89186, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "test_labels = pd.read_csv('test_labels.csv', index_col = 0)\n",
    "print(test_labels.head())\n",
    "labelled_test = test.join(test_labels)\n",
    "disclosed = labelled_test.toxic>-1\n",
    "print(disclosed .mean(),'% of test is labelled')\n",
    "train = train.append(labelled_test[disclosed])\n",
    "test = labelled_test[~disclosed][['comment_text']]\n",
    "print(train.shape,test.shape)\n",
    "#train.to_csv('tc_train.csv')\n",
    "#test.to_csv('tc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "id                                                                           \n",
       "00001cee341fdb12     -1            -1       -1      -1      -1             -1\n",
       "0000247867823ef7     -1            -1       -1      -1      -1             -1\n",
       "00013b17ad220c46     -1            -1       -1      -1      -1             -1\n",
       "00017563c3f7919a     -1            -1       -1      -1      -1             -1\n",
       "00017695ad8997eb     -1            -1       -1      -1      -1             -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89186, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "for col in test_labels.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(file_name):\n",
    "    embeddings_index = {}\n",
    "    with open(file_name, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # remove white spaces and split\n",
    "            values = line.rstrip().split(' ')\n",
    "            if len(values) > 2:\n",
    "                embeddings_index[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = get_embeddings('crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', 'is', 'for', 'that', 'I', 'it', 'on', 'with', ')', ':', '\"', '(', 'The', 'you', 'was', 'are', 'or', 'this']\n",
      "\n",
      "First key:  , \n",
      "\n",
      "Vector length:  300 \n",
      "\n",
      "Vector for first key:  [-2.820e-02 -5.570e-02 -4.510e-02 -4.340e-02  7.120e-02 -8.550e-02\n",
      " -1.085e-01 -5.610e-02 -4.523e-01 -2.020e-02  9.750e-02  1.047e-01\n",
      "  1.962e-01 -6.930e-02  2.130e-02 -2.350e-02  1.336e-01 -4.200e-02\n",
      " -5.640e-02 -7.980e-02  4.240e-02 -4.090e-02 -5.360e-02 -2.520e-02\n",
      "  1.350e-02  6.400e-03  1.235e-01  4.610e-02  1.200e-02 -3.720e-02\n",
      "  6.500e-02  4.100e-03 -1.074e-01 -2.630e-02  1.133e-01 -2.900e-03\n",
      "  6.710e-02  1.065e-01  2.340e-02 -1.600e-02  7.000e-03  4.355e-01\n",
      " -7.520e-02 -4.328e-01  4.570e-02  6.040e-02 -7.400e-02 -5.500e-03\n",
      " -8.900e-03 -2.926e-01 -5.450e-02 -1.519e-01  9.900e-02 -1.930e-02\n",
      " -5.000e-03  5.110e-02  4.040e-02  1.023e-01 -1.280e-02  4.880e-02\n",
      " -1.567e-01 -7.590e-02 -1.900e-02  1.442e-01  4.700e-03 -1.860e-02\n",
      "  1.400e-02 -3.850e-02 -8.530e-02  1.572e-01  1.770e-01  8.400e-03\n",
      " -2.500e-02 -1.145e-01 -6.630e-02 -1.244e-01 -3.977e-01 -1.240e-02\n",
      " -4.586e-01 -2.200e-02  5.746e-01  2.180e-02 -7.540e-02  9.900e-03\n",
      "  3.970e-02 -1.540e-02  4.240e-02 -1.500e-02 -1.600e-03  3.050e-02\n",
      "  1.010e-02  2.266e-01  1.394e-01  1.890e-02  6.900e-03  3.940e-02\n",
      "  3.550e-02 -1.110e-02 -6.870e-02 -7.800e-03  2.240e-02  8.170e-02\n",
      " -1.949e-01  1.000e-04  4.047e-01 -2.370e-02 -6.560e-02 -6.840e-02\n",
      "  2.330e-02  4.380e-02  1.203e-01 -2.760e-02  4.160e-02  1.140e-02\n",
      " -4.529e-01  1.538e-01  1.323e-01 -1.860e-02 -9.140e-02 -3.120e-02\n",
      "  1.051e-01  2.120e-02  7.980e-02 -1.040e-02 -2.060e-02 -2.500e-03\n",
      "  4.300e-03 -3.780e-02  2.689e-01  7.470e-02 -4.180e-02 -4.800e-03\n",
      " -3.870e-02  4.320e-02  1.704e-01  6.140e-02  9.050e-02 -4.360e-02\n",
      " -1.410e-02 -3.150e-02  2.760e-02  1.510e-02 -1.030e-02 -2.660e-02\n",
      " -5.120e-02 -4.080e-02 -6.510e-02  6.620e-02 -9.360e-02  1.371e-01\n",
      "  4.580e-02 -1.366e-01 -7.500e-03 -1.040e-02 -7.320e-02  1.205e-01\n",
      "  1.035e-01  1.060e-02 -3.170e-02 -3.160e-02  6.639e-01 -2.200e-03\n",
      " -1.343e-01  1.440e-02 -3.380e-02  3.400e-03 -4.290e-02 -8.210e-02\n",
      "  3.700e-03  1.029e-01 -2.040e-02 -2.690e-02  5.200e-03 -1.034e-01\n",
      "  1.068e-01  1.210e-02  9.800e-02 -4.580e-02  1.990e-02 -1.320e-02\n",
      "  1.936e-01 -2.130e-02  2.090e-02 -2.500e-03  4.160e-02 -3.370e-02\n",
      "  5.160e-02 -1.014e-01  2.030e-02  1.980e-02 -3.050e-02 -3.130e-02\n",
      "  5.430e-02 -1.060e-02  1.441e-01 -1.780e-02 -6.270e-02  4.750e-02\n",
      "  3.520e-02 -2.540e-02 -9.490e-02  4.010e-02  3.170e-02  5.500e-03\n",
      " -5.360e-02  1.910e-02 -5.110e-02 -4.090e-02 -3.000e-03  1.582e-01\n",
      "  1.080e-02  5.237e-01  4.360e-02  3.060e-02 -3.920e-02  1.770e-02\n",
      "  6.900e-03  6.050e-02  1.206e-01 -2.160e-02 -6.330e-02 -2.965e-01\n",
      "  5.210e-02 -1.500e-02 -2.207e-01 -6.420e-02 -9.060e-02 -1.210e-02\n",
      "  5.690e-02  9.440e-02 -6.520e-02 -1.080e-02 -4.770e-02  2.300e-03\n",
      "  7.700e-03 -1.547e-01  4.630e-02  6.980e-02 -3.760e-02 -2.910e-02\n",
      "  3.300e-03 -1.020e-02 -7.430e-02  8.500e-03  8.050e-02 -2.910e-02\n",
      " -6.740e-02 -5.860e-02 -6.530e-02  2.830e-02 -2.550e-02  8.690e-02\n",
      " -8.680e-02  9.000e-03  3.245e-01 -5.730e-02 -2.890e-02  4.700e-02\n",
      " -1.170e-02  1.740e-02  1.320e-02 -2.260e-02 -6.640e-02  1.880e-02\n",
      "  2.630e-02  1.110e-02 -4.900e-03 -6.560e-02  2.950e-02  4.350e-02\n",
      "  2.900e-02  1.163e-01  4.480e-02 -1.139e-01 -5.530e-02 -5.280e-02\n",
      "  1.745e-01 -1.460e-02 -1.308e-01 -6.070e-02 -1.340e-02  7.810e-02\n",
      "  3.780e-02  2.280e-02 -7.280e-02 -5.900e-03  1.580e-02 -1.410e-02\n",
      " -2.000e-04  1.930e-02 -1.480e-02 -4.630e-02  4.440e-02  3.034e-01\n",
      "  1.020e-01 -8.710e-02  3.170e-02 -3.700e-02 -7.250e-02 -4.200e-03]\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddings_index.keys())[:25])\n",
    "ke,va = list(embeddings_index.items())[0]\n",
    "print('\\nFirst key: ',ke,'\\n\\nVector length: ',len(va),'\\n\\nVector for first key: ',va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", True\n",
      "! True\n",
      "!! False\n",
      "it's True\n",
      "I'll True\n",
      "* True\n",
      "> True\n",
      "¿ True\n",
      "£ True\n",
      "' True\n",
      "’ True\n"
     ]
    }
   ],
   "source": [
    "for word in [',','!','!!',\"it's\",\"I'll\",'*','>','¿','£',\"'\",\"’\"]:\n",
    "    print(word, word in embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "Labels: \n",
      " id\n",
      "0000997932d777bf    000000\n",
      "000103f0d9cfb60f    000000\n",
      "000113f07ec002fd    000000\n",
      "0001b41b1c6bb37e    000000\n",
      "0001d958c54c6e35    000000\n",
      "dtype: object\n",
      "\n",
      "Counts of labels: \n",
      " 000000    201081\n",
      "100000      7376\n",
      "101010      5732\n",
      "101000      2612\n",
      "100010      1754\n",
      "111010      1165\n",
      "101011       979\n",
      "111011       381\n",
      "001000       366\n",
      "000010       365\n",
      "100011       215\n",
      "100001       203\n",
      "101110       196\n",
      "001010       196\n",
      "111000       186\n",
      "100100       163\n",
      "111110        88\n",
      "101111        81\n",
      "000001        68\n",
      "101001        55\n",
      "111111        45\n",
      "110000        41\n",
      "000011        32\n",
      "000100        27\n",
      "100110        25\n",
      "001011        19\n",
      "101100        17\n",
      "110010        14\n",
      "100101        11\n",
      "110100        11\n",
      "111100         8\n",
      "111001         7\n",
      "110011         7\n",
      "110101         5\n",
      "rare           5\n",
      "000110         4\n",
      "001001         3\n",
      "110001         3\n",
      "100111         3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "types = list(train)[1:]\n",
    "print(types)\n",
    "\n",
    "# convert each vector of labels to the string\n",
    "labels = train[types].astype(str).apply(lambda x: ''.join(x),axis=1)\n",
    "print('Labels: \\n',labels.head())\n",
    "# aggregate rare combinations if any\n",
    "count = labels.value_counts()\n",
    "rare = count.index[count<=2]\n",
    "labels[np.isin(labels.values,rare)] = 'rare'\n",
    "print('\\nCounts of labels: \\n',labels.value_counts())\n",
    "train_index, val_index = train_test_split(train.index, test_size=0.2, \n",
    "                                      stratify = labels, random_state=0)\n",
    "# save train and validation indices for further calculations\n",
    "fname = 'train_val_split.pkl'\n",
    "with open(fname, 'wb') as f: pickle.dump([train_index, val_index], f, -1),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess text with the function preprocess() \n",
    "### Step 4: Using CountVectorizer from sklearn package create the vocabulary of all words from comments except rare ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "trans_table = str.maketrans({key: ' ' for key in string.digits + '\\r\\n' +\n",
    "                             string.punctuation.replace(\"\\'\",'')})\n",
    "def preprocess(text):\n",
    "    return ' '.join(text.lower().translate(trans_table).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the vocabulary of words occurred more than 5\n",
      "45259 top words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "UNKNOWN_PROXY = 'unknown'\n",
    "MIN_WORD_OCCURRENCE = 5\n",
    "\n",
    "train['comment_text'] = train.comment_text.apply(preprocess)\n",
    "print(\"Creating the vocabulary of words occurred more than\", MIN_WORD_OCCURRENCE)\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False, token_pattern=\"\\S+\", \n",
    "                             min_df=MIN_WORD_OCCURRENCE)\n",
    "vectorizer.fit(train.comment_text)\n",
    "\n",
    "top_words = set(vectorizer.vocabulary_.keys())\n",
    "top_words.add(UNKNOWN_PROXY)\n",
    "print(len(top_words),'top words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 out of \"top_words\": \n",
      " ['inheritance', 'timing', 'interaction', 'whitespace', 'considerable', 'trad', 'dramatic', 'discard', 'vpn', 'gerald']\n",
      "\n",
      "Is \"unknown\" in top_words? \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "print('First 10 out of \"top_words\": \\n',list(top_words)[:10])\n",
    "print('\\nIs \"unknown\" in top_words? \\n','unknown' in top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Prepare input data for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x1245eed30>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(train.comment_text)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 1),\n",
       " ('to', 2),\n",
       " ('of', 3),\n",
       " ('and', 4),\n",
       " ('a', 5),\n",
       " ('you', 6),\n",
       " ('i', 7),\n",
       " ('is', 8),\n",
       " ('that', 9),\n",
       " ('in', 10),\n",
       " ('it', 11),\n",
       " ('for', 12),\n",
       " ('this', 13),\n",
       " ('not', 14),\n",
       " ('on', 15),\n",
       " ('be', 16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "list(word_index.items())[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 2 sequences in `seq`:  [[676, 77, 1, 133, 130, 177, 30, 666, 4436, 11406, 1126, 85, 349, 51, 2184, 12587, 50, 6354, 15, 59, 2567, 148, 7, 2795, 33, 116, 1196, 15967, 2453, 4, 47, 60, 247, 1, 359, 31, 1, 41, 27, 143, 71, 3503, 89], [121402, 52, 2765, 13, 466, 3656, 71, 4530, 2696, 21, 93, 41, 968, 196]]\n",
      "\n",
      "Shape of `data`:  (223549, 100)\n",
      "\n",
      "First prepared text in `data`: [  676    77     1   133   130   177    30   666  4436 11406  1126    85\n",
      "   349    51  2184 12587    50  6354    15    59  2567   148     7  2795\n",
      "    33   116  1196 15967  2453     4    47    60   247     1   359    31\n",
      "     1    41    27   143    71  3503    89     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "seq = tokenizer.texts_to_sequences(train.comment_text)\n",
    "data = pad_sequences(seq,maxlen=MAX_SEQUENCE_LENGTH,padding='post',\n",
    "                     truncating='post')\n",
    "with open('toxic_data.pkl','wb') as f: pickle.dump(data, f, -1)\n",
    "\n",
    "print('\\nFirst 2 sequences in `seq`: ',seq[:2])\n",
    "print('\\nShape of `data`: ',data.shape)\n",
    "print('\\nFirst prepared text in `data`:',data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_1\n",
      "word_2\n",
      "word_3\n",
      "enough\n",
      "enough\n"
     ]
    }
   ],
   "source": [
    "mlist=['word_1','word_2','word_3']\n",
    "moveIter=iter(mlist)\n",
    "print(next(moveIter,'enough'))\n",
    "print(next(moveIter,'enough'))\n",
    "print(next(moveIter,'enough'))\n",
    "print(next(moveIter,'enough'))\n",
    "print(next(moveIter,'enough'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dim = len(next(iter(embeddings_index.values())))\n",
    "embeddings_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(word_index,embeddings_index):\n",
    "    nb_words = len(word_index) + 1 # +1 since min(word_index.values())=1\n",
    "    embedding_matrix = np.zeros((nb_words,embeddings_dim))\n",
    "    unknown = 0\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None: unknown += 1\n",
    "        else: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix, unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160113 unknown words\n"
     ]
    }
   ],
   "source": [
    "def make_save_emb_layer(word_index,embeddings_index,layer_file_name):\n",
    "    embedding_matrix,unknown = get_embedding_matrix(word_index,embeddings_index)\n",
    "    embedding_layer = Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],\n",
    "                                weights=[embedding_matrix],trainable=False)\n",
    "    with open(layer_file_name,'wb') as f: \n",
    "        pickle.dump(embedding_layer, f, -1)\n",
    "    return unknown\n",
    "\n",
    "EMBEDDING_LAYER_FILE = 'toxic_embed_layer.pkl'\n",
    "print(make_save_emb_layer(word_index,embeddings_index,EMBEDDING_LAYER_FILE),\n",
    "      'unknown words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Split train data into train and validation sets using the method of multilabel dataset splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create neural network, tune it on train and validation sets and make submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Embedding,Input,Dropout,Conv1D\n",
    "from keras.layers import SpatialDropout1D, Flatten,LSTM, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    x = embedding_layer(input_layer)\n",
    "    x = SpatialDropout1D(0.5)(x)\n",
    "    x = LSTM(10, return_sequences=True)(x)\n",
    "    x = Conv1D(5, kernel_size=2, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    output_layer = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EMBEDDING_LAYER_FILE, 'rb') as f: embedding_layer = pickle.load(f)\n",
    "with open('toxic_data.pkl', 'rb') as f: data = pickle.load(f)   \n",
    "    \n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "max_features = 100000\n",
    "maxlen = 100\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, test_size=0.2, \n",
    "                                stratify = train.toxic, random_state=0)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, train.toxic, test_size=0.2, stratify = train.toxic, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          84155700  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 10)           12440     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 99, 5)             105       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 36        \n",
      "=================================================================\n",
      "Total params: 84,168,301\n",
      "Trainable params: 12,591\n",
      "Non-trainable params: 84,155,710\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'best_model.h5'\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "model_checkpoint = ModelCheckpoint(best_model_path,\n",
    "                                   save_best_only=True, save_weights_only=True)\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='toxic_reviews.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178839 samples, validate on 44710 samples\n",
      "Epoch 1/28\n",
      " - 75s - loss: 0.5742 - val_loss: 0.4237\n",
      "Epoch 2/28\n",
      " - 79s - loss: 0.2286 - val_loss: 0.1475\n",
      "Epoch 3/28\n",
      " - 83s - loss: 0.1374 - val_loss: 0.1061\n",
      "Epoch 4/28\n",
      " - 79s - loss: 0.1162 - val_loss: 0.0920\n",
      "Epoch 5/28\n",
      " - 77s - loss: 0.1064 - val_loss: 0.0843\n",
      "Epoch 6/28\n",
      " - 74s - loss: 0.1011 - val_loss: 0.0806\n",
      "Epoch 7/28\n",
      " - 75s - loss: 0.0968 - val_loss: 0.0790\n",
      "Epoch 8/28\n",
      " - 78s - loss: 0.0941 - val_loss: 0.0771\n",
      "Epoch 9/28\n",
      " - 79s - loss: 0.0924 - val_loss: 0.0739\n",
      "Epoch 10/28\n",
      " - 73s - loss: 0.0899 - val_loss: 0.0719\n",
      "Epoch 11/28\n",
      " - 73s - loss: 0.0887 - val_loss: 0.0710\n",
      "Epoch 12/28\n",
      " - 73s - loss: 0.0877 - val_loss: 0.0710\n",
      "Epoch 13/28\n",
      " - 73s - loss: 0.0865 - val_loss: 0.0695\n",
      "Epoch 14/28\n",
      " - 72s - loss: 0.0860 - val_loss: 0.0723\n",
      "Epoch 15/28\n",
      " - 73s - loss: 0.0848 - val_loss: 0.0684\n",
      "Epoch 16/28\n",
      " - 72s - loss: 0.0840 - val_loss: 0.0683\n",
      "Epoch 17/28\n",
      " - 73s - loss: 0.0835 - val_loss: 0.0683\n",
      "Epoch 18/28\n",
      " - 74s - loss: 0.0825 - val_loss: 0.0678\n",
      "Epoch 19/28\n",
      " - 74s - loss: 0.0815 - val_loss: 0.0672\n",
      "Epoch 20/28\n",
      " - 72s - loss: 0.0809 - val_loss: 0.0672\n",
      "Epoch 21/28\n",
      " - 73s - loss: 0.0806 - val_loss: 0.0692\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_tra, y_tra,validation_data=(X_val, y_val),\n",
    "                 epochs=28, batch_size=BATCH_SIZE, shuffle=True, verbose=2,\n",
    "                 callbacks=[model_checkpoint, early_stopping])\n",
    "model.load_weights(best_model_path)\n",
    "#test_pred = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "#print('validation AUC',roc_auc_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 2 sequences in `seq`:  [[1979, 375, 4749, 709, 8, 58, 20594, 84, 864, 347, 16, 3375, 73, 21, 6, 5, 6053, 6, 1514, 7, 56, 375, 5329, 1450, 569, 5719, 5, 94, 6, 2, 3698, 30, 338, 6, 727, 33525, 37, 4749, 709, 8, 35, 4124, 10, 1159, 641, 396, 474, 16917, 9, 225, 15, 154, 5, 19764, 8, 246, 23228, 48, 4235, 52, 24, 3, 2064, 155, 2377, 569, 2372, 94, 216, 143, 487, 85], [31, 1113, 1, 337, 8, 653, 17, 11, 8, 2666]]\n",
      "\n",
      "Shape of `data`:  (89186, 100)\n",
      "\n",
      "First prepared text in `data`: [ 1979   375  4749   709     8    58 20594    84   864   347    16  3375\n",
      "    73    21     6     5  6053     6  1514     7    56   375  5329  1450\n",
      "   569  5719     5    94     6     2  3698    30   338     6   727 33525\n",
      "    37  4749   709     8    35  4124    10  1159   641   396   474 16917\n",
      "     9   225    15   154     5 19764     8   246 23228    48  4235    52\n",
      "    24     3  2064   155  2377   569  2372    94   216   143   487    85\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "seq_test = tokenizer.texts_to_sequences(test.comment_text)\n",
    "data_test = pad_sequences(seq_test,maxlen=MAX_SEQUENCE_LENGTH,padding='post',\n",
    "                     truncating='post')\n",
    "with open('toxic_datatest.pkl','wb') as f: pickle.dump(data, f, -1)\n",
    "\n",
    "print('\\nFirst 2 sequences in `seq`: ',seq_test[:2])\n",
    "print('\\nShape of `data`: ',data_test.shape)\n",
    "print('\\nFirst prepared text in `data`:',data_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict(data_test, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89186, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5263243e-01, 3.3659378e-01, 9.3635964e-01, 9.3622863e-02,\n",
       "        8.7981492e-01, 2.5662792e-01],\n",
       "       [1.9645900e-02, 1.2114048e-03, 4.4161081e-03, 1.2894571e-03,\n",
       "        7.0632994e-03, 3.6766827e-03],\n",
       "       [7.2258413e-03, 8.2850456e-04, 1.3550520e-03, 1.1959672e-03,\n",
       "        2.7394295e-03, 2.7734339e-03],\n",
       "       [1.5315324e-02, 7.2389841e-05, 3.3738613e-03, 3.5136938e-05,\n",
       "        4.1226745e-03, 3.7014484e-04],\n",
       "       [1.0709912e-02, 1.2480021e-03, 2.1812320e-03, 1.9345582e-03,\n",
       "        4.1436553e-03, 4.0555298e-03]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fin = pd.DataFrame(test_result, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fin.columns = ['toxic','severe_toxic','obscene',\n",
    "                     'threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.336594</td>\n",
       "      <td>0.936360</td>\n",
       "      <td>0.093623</td>\n",
       "      <td>0.879815</td>\n",
       "      <td>0.256628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0.019646</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.003677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.004056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "id                                                                       \n",
       "00001cee341fdb12  0.952632      0.336594  0.936360  0.093623  0.879815   \n",
       "0000247867823ef7  0.019646      0.001211  0.004416  0.001289  0.007063   \n",
       "00013b17ad220c46  0.007226      0.000829  0.001355  0.001196  0.002739   \n",
       "00017563c3f7919a  0.015315      0.000072  0.003374  0.000035  0.004123   \n",
       "00017695ad8997eb  0.010710      0.001248  0.002181  0.001935  0.004144   \n",
       "\n",
       "                  identity_hate  \n",
       "id                               \n",
       "00001cee341fdb12       0.256628  \n",
       "0000247867823ef7       0.003677  \n",
       "00013b17ad220c46       0.002773  \n",
       "00017563c3f7919a       0.000370  \n",
       "00017695ad8997eb       0.004056  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fin.to_csv('tc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmUnHWd7/H3t/d9Sbo6ZCMJIWmTQEhIE1kkaUaILAo6OogMXnVmhLlXRz0uI8y4HLnXezk6ctERFRRG56owCOphBlTWJCAgWUCWhGwQSCck3Vl7Se/9vX88T3dXdzrd1Ut1VXV9XufU6apnqfoGkvr083u+z+8xd0dERGQoGYkuQEREkp/CQkREhqWwEBGRYSksRERkWAoLEREZlsJCRESGpbAQGQdm9lMz+18xbrvbzC4e6/uITCSFhYiIDEthISIiw1JYSNoIh3++ZGYvmVmzmd1lZtPM7Hdm1mhmj5lZedT2V5rZq2Z21MzWmtmiqHXLzWxzuN9/AHkDPuu9ZvZiuO8zZrZ0lDV/0sx2mtlhM3vQzGaEy83M/q+Z1ZnZsfDPdEa47nIz2xLWttfMvjiq/2AiURQWkm4+CFwCLATeB/wO+CegguDfw2cAzGwhcA/wOSACPAz8p5nlmFkO8Fvg/wFTgF+F70u479nA3cANwFTgDuBBM8sdSaFm9hfA/wGuBqYDbwL3hqvXAKvCP0cZ8GHgULjuLuAGdy8GzgCeGMnnigxGYSHp5l/d/YC77wWeAv7k7i+4exvwG2B5uN2HgYfc/VF37wD+BcgHzgfOBbKB29y9w93vBzZEfcYngTvc/U/u3uXuPwPawv1G4q+Bu919c1jfTcB5ZjYX6ACKgXcA5u5b3f3tcL8OYLGZlbj7EXffPMLPFTmBwkLSzYGo5y2DvC4Kn88g+E0eAHfvBvYAM8N1e73/LJxvRj2fA3whHII6amZHgdnhfiMxsIYmgqOHme7+BPB94HbggJndaWYl4aYfBC4H3jSzdWZ23gg/V+QECguRwe0j+NIHgnMEBF/4e4G3gZnhsh6nRj3fA3zT3cuiHgXufs8YaygkGNbaC+Du33P3FcASguGoL4XLN7j7VUAlwXDZfSP8XJETKCxEBncfcIWZvdvMsoEvEAwlPQM8C3QCnzGzLDP7S2Bl1L4/Bv7ezN4ZnoguNLMrzKx4hDX8EviEmS0Lz3f8b4Jhs91mdk74/tlAM9AKdIXnVP7azErD4bMGoGsM/x1EAIWFyKDcfRtwHfCvwEGCk+Hvc/d2d28H/hL4OHCE4PzGr6P23Uhw3uL74fqd4bYjreFx4KvAAwRHM/OBa8LVJQShdIRgqOoQwXkVgI8Cu82sAfj78M8hMiammx+JiMhwdGQhIiLDUliIiMiwFBYiIjIshYWIiAwrK9EFjJeKigqfO3duossQEUkpmzZtOujukeG2mzRhMXfuXDZu3JjoMkREUoqZvTn8VhqGEhGRGCgsRERkWAoLEREZ1qQ5ZyEiMhodHR3U1tbS2tqa6FLiKi8vj1mzZpGdnT2q/RUWIpLWamtrKS4uZu7cufSfSHjycHcOHTpEbW0t8+bNG9V7aBhKRNJaa2srU6dOnbRBAWBmTJ06dUxHTwoLEUl7kzkoeoz1z5j2YXH0eDvffWwHr+47luhSRESSVtqHhZnxvSd28PDLbw+/sYjIODt69Cg/+MEPRrzf5ZdfztGjR+NQ0eDSPixK87NZcWo5a7fVJ7oUEUlDJwuLrq6hb3D48MMPU1ZWFq+yTpD2YQFQ844Ir+5roK5xcrfOiUjyufHGG9m1axfLli3jnHPO4aKLLuLaa6/lzDPPBOD9738/K1asYMmSJdx55529+82dO5eDBw+ye/duFi1axCc/+UmWLFnCmjVraGlpGfc61ToL1Cys5Fu/38a6bfX8VfXsRJcjIgnyjf98lS37Gsb1PRfPKOHr71ty0vW33HILr7zyCi+++CJr167liiuu4JVXXultcb377ruZMmUKLS0tnHPOOXzwgx9k6tSp/d5jx44d3HPPPfz4xz/m6quv5oEHHuC668b3bro6sgAWTS9mWkkua7drKEpEEmvlypX9roX43ve+x1lnncW5557Lnj172LFjxwn7zJs3j2XLlgGwYsUKdu/ePe516ciC4CT36oURfv/Kfjq7usnKVIaKpKOhjgAmSmFhYe/ztWvX8thjj/Hss89SUFBATU3NoNdK5Obm9j7PzMyMyzCUvhVDNVWVNLR28sKeiesuEBEpLi6msbFx0HXHjh2jvLycgoICXnvtNZ577rkJrq6PjixCF5xeQWaGsXZbHefMnZLockQkTUydOpULLriAM844g/z8fKZNm9a77tJLL+VHP/oRS5cupaqqinPPPTdhdZq7J+zDx1N1dbWP9eZHV//oWZrbO3noMxeOU1Uikuy2bt3KokWLEl3GhBjsz2pmm9y9erh94zoMZWaXmtk2M9tpZjcOsv7vzexlM3vRzJ42s8VR624K99tmZu+JZ509VlephVZEZDBxCwszywRuBy4DFgMfiQ6D0C/d/Ux3XwZ8C7g13HcxcA2wBLgU+EH4fnFVUxXchnadLtATEeknnkcWK4Gd7v66u7cD9wJXRW/g7tENzYVAz5jYVcC97t7m7m8AO8P3i6vF00uoLFYLrYjIQPEMi5nAnqjXteGyfszsU2a2i+DI4jMj3Pd6M9toZhvr68f+Bd/TQvvU9no6u7rH/H4iIpNFPMNisPlwTzib7u63u/t84MvAV0a4753uXu3u1ZFIZEzF9uhpoX1RLbQiIr3iGRa1QPTcGbOAfUNsfy/w/lHuO27etaCnhVZDUSIiPeIZFhuABWY2z8xyCE5YPxi9gZktiHp5BdBzHfuDwDVmlmtm84AFwPNxrLVXaX42Z59axtrtdRPxcSKS5kY7RTnAbbfdxvHjx8e5osHFLSzcvRP4NPAHYCtwn7u/amY3m9mV4WafNrNXzexF4PPAx8J9XwXuA7YAvwc+5e5Dz9c7jmqqKnllr1poRST+UiUs4noFt7s/DDw8YNnXop5/doh9vwl8M37VndzqhRG+/YdtrN9+kA+tmJWIEkQkTURPUX7JJZdQWVnJfffdR1tbGx/4wAf4xje+QXNzM1dffTW1tbV0dXXx1a9+lQMHDrBv3z4uuugiKioqePLJJ+Nap6b7GMSSGSVEinNZu61OYSGSTn53I+x/eXzf85Qz4bJbTro6eoryRx55hPvvv5/nn38ed+fKK69k/fr11NfXM2PGDB566CEgmDOqtLSUW2+9lSeffJKKiorxrXkQmkhwEL0ttDsOqoVWRCbMI488wiOPPMLy5cs5++yzee2119ixYwdnnnkmjz32GF/+8pd56qmnKC0tnfDadGRxEjVVEe7fVMufa4+yYo4mFhRJC0McAUwEd+emm27ihhtuOGHdpk2bePjhh7nppptYs2YNX/va1wZ5h/jRkcVJXHh6hAxDLbQiElfRU5S/5z3v4e6776apqQmAvXv3UldXx759+ygoKOC6667ji1/8Ips3bz5h33jTkcVJlBZkc/ap5azdVs8X1lQluhwRmaSipyi/7LLLuPbaaznvvPMAKCoq4uc//zk7d+7kS1/6EhkZGWRnZ/PDH/4QgOuvv57LLruM6dOnx/0Et6YoH8L3n9jBvzyynQ3/fDGR4tzhdxCRlKMpypNgivJUV1NVCcB6TSwoImlOYTGExdNLqCjSLLQiIgqLIWRk9LTQ1tPVPTmG60TkRJNlOH4oY/0zKiyGUVMV4ejxDs1CKzJJ5eXlcejQoUkdGO7OoUOHyMvLG/V7qBtqGBcuqCDDYN22OlbMKU90OSIyzmbNmkVtbS3jcU+cZJaXl8esWaOfkUJhMYyyghyWn1rO2u31fF4ttCKTTnZ2NvPmzUt0GUlPw1AxqFkY4aXaYxxsakt0KSIiCaGwiIFaaEUk3SksYrBkRgkVRTma+kNE0pbCIgYZGcaqhRHWq4VWRNKUwiJGNVWVHD3ewZ9r1UIrIulHYRGjVWELrYaiRCQdKSxiVFaQw7LZZazbVpfoUkREJpzCYgRqqip5ae8xDqmFVkTSjMJiBGqqIrjD+h0aihKR9KKwGIEzZpSqhVZE0pLCYgQyMoxVCyKs364WWhFJLwqLEVpdFeHI8Q5eUgutiKQRhcUIrVoQUQutiKQdhcUIlRfmcNbsMt09T0TSisJiFGoWVvJS7VG10IpI2lBYjEJPC+1TOw4muhQRkQmhsBiFM2eWMrUwh7W6mltE0oTCYhT6ZqE9SLdaaEUkDSgsRqmmKsLh5nZe2nss0aWIiMSdwmKULlwQwQwNRYlIWlBYjNKUwhzOmlWm6y1EJC0oLMagpirCn2uPcri5PdGliIjElcJiDGqqKsMWWh1diMjkprAYg6UzS5lSqFloRWTyU1iMQTALbQXrt9erhVZEJjWFxRjVVFVyqLmdl9VCKyKTmMJijFYt7Gmh1VCUiExecQ0LM7vUzLaZ2U4zu3GQ9Z83sy1m9pKZPW5mc6LWdZnZi+HjwXjWORZTCnNYOquMtdt1vYWITF5xCwszywRuBy4DFgMfMbPFAzZ7Aah296XA/cC3ota1uPuy8HFlvOocDzULI7y4Ry20IjJ5xfPIYiWw091fd/d24F7gqugN3P1Jdz8evnwOmBXHeuKmbxZaDUWJyOQUz7CYCeyJel0bLjuZvwV+F/U6z8w2mtlzZvb+wXYws+vDbTbW1yfui3rprDLKC7J13kJEJq2sOL63DbJs0P5SM7sOqAZWRy0+1d33mdlpwBNm9rK77+r3Zu53AncCVFdXJ6x3NbNnFtqwhTYjY7A/uohI6ornkUUtMDvq9Sxg38CNzOxi4J+BK92999Zz7r4v/Pk6sBZYHsdax6ymKqIWWhGZtOIZFhuABWY2z8xygGuAfl1NZrYcuIMgKOqilpebWW74vAK4ANgSx1rHbNUCtdCKyOQVt7Bw907g08AfgK3Afe7+qpndbGY93U3fBoqAXw1okV0EbDSzPwNPAre4e1KHxdSiXJbOLFULrYhMSvE8Z4G7Pww8PGDZ16KeX3yS/Z4BzoxnbfGwuqqSf31iB0ea2ykvzEl0OSIi40ZXcI+jnhba9WqhFZFJRmExjs4KW2jX6byFiEwyCotxlJlhXLggwjrNQisik4zCYpz1tNC+sk8ttCIyeSgsxtmqhRFALbQiMrkoLMZZRVEuS2eVsnabWmhFZPJQWMRBzyy0R49rFloRmRwUFnGwuqqSbof1Ow4muhQRkXGhsIiDZbPLKCvI1lCUiEwaCos46GmhXa8WWhGZJBQWcVKzMMLBpnZe3deQ6FJERMZMYREnfS20GooSkdSnsIiTSHHYQrtd11uISOpTWMRRzcIIL7x1RC20IpLyFBZx1NNC+5RaaEUkxSks4qivhVZDUSKS2hQWcaRZaEVkslBYxFnQQtvGlrfVQisiqUthEWdqoRWRyUBhEWeR4lzOnFmq8xYiktIUFhOgpirC5reOcOx4R6JLEREZFYXFBKipigQttDt1dCEiqUlhMQGWzS6nNF8ttCKSuhQWEyBooa1QC62IpCyFxQSpqaqkvlEttCKSmhQWE2R12EK7ThMLikgKUlhMkEhxLmfMLNH1FiKSkmIKCzP7rJmVWOAuM9tsZmviXdxkU7Owks1vHeVYi1poRSS1xHpk8Tfu3gCsASLAJ4Bb4lbVJFVTFaGr23las9CKSIqJNSws/Hk58G/u/ueoZRKjZbPLKMnL0lCUiKScWMNik5k9QhAWfzCzYqA7fmVNTlmZGVy4MJiF1l0ttCKSOmINi78FbgTOcffjQDbBUJSMUM3CCHVqoRWRFBNrWJwHbHP3o2Z2HfAV4Fj8ypq8Vlf1zEKrFloRSR2xhsUPgeNmdhbwj8CbwL/HrapJrLI4jyUzSlinsBCRFBJrWHR6MMh+FfBdd/8uUBy/sia3mqoIm946ohZaEUkZsYZFo5ndBHwUeMjMMgnOW8go1FRV0tXt/HGnWmhFJDXEGhYfBtoIrrfYD8wEvh23qia55WqhFZEUE1NYhAHxC6DUzN4LtLq7zlmMUlZmBhcuUAutiKSOWKf7uBp4Hvgr4GrgT2b2oXgWNtmtropwoKGNrW83JroUEZFhxToM9c8E11h8zN3/G7AS+OpwO5nZpWa2zcx2mtmNg6z/vJltMbOXzOxxM5sTte5jZrYjfHws1j9QqqgJZ6Fdu11DUSKS/GINiwx3j/5WOzTcvuFJ8NuBy4DFwEfMbPGAzV4Aqt19KXA/8K1w3ynA14F3EgTT182sPMZaU0JlSR6Lp5foegsRSQmxhsXvzewPZvZxM/s48BDw8DD7rAR2uvvr7t4O3EvQetvL3Z8MrwgHeA6YFT5/D/Coux929yPAo8ClMdaaMmqqImx68wgNrWqhFZHkFusJ7i8BdwJLgbOAO939y8PsNhPYE/W6Nlx2Mn8L/G4k+5rZ9Wa20cw21ten3m/ovS20moVWRJJcVqwbuvsDwAMjeO/BZqUdtPUnnEKkGlg9kn3d/U6CEKO6ujrl2orOPrWM4rws1m6r57Izpye6HBGRkxoyLMyskcG/4A1wdy8ZYvdaYHbU61nAvkE+42KCE+ir3b0tat+aAfuuHarWVBS00Fb0ttCaadZ3EUlOQw5DuXuxu5cM8igeJigANgALzGyemeUA1wAPRm9gZsuBO4ArB5xA/wOwxszKwxPba8Jlk07Nwkr2N7Ty2n610IpI8orbPbjdvRP4NMGX/FbgPnd/1cxuNrMrw82+DRQBvzKzF83swXDfw8D/JAicDcDN4bJJR7PQikgqsMlyBXF1dbVv3Lgx0WWMymXffYrivCzuu+G8RJciImnGzDa5e/Vw28XtyEJipxZaEUl2CoskULMwohZaEUlqCoskcPaccopzs3TeQkSSlsIiCWRnZvCuqBZaEZFko7BIEjVVEbXQikjSUlgkidULKwG10IpIclJYJIlTSvN4xynFunueiCQlhUUSqamqZNObR2hUC62IJBmFRRKpqYrQ2e38cadaaEUkuSgsksgKtdCKSJJSWCSR7MwMLji9grXb1EIrIslFYZFkelpotx1QC62IJA+FRZLRLLQikowUFklmemm+WmhFJOkoLJLQ6qoIG3erhVZEkofCIgnVLKwMW2gPJboUERFAYZGUqueWU5SbxbrtGooSkeSgsEhCQQvtVLXQikjSUFgkqZqqSt4+1sr2A02JLkVERGGRrGp6W2g1FCUiiaewSFLTS/Opmlas6y1EJCkoLJJYTVWEjW8epqmtM9GliEiaU1gksdVVETq6NAutiCSewiKJVc+ZQmFOpoaiRCThFBZJLCcrmIV23bY6tdCKSEIpLJJcTVUl+461sqNOLbQikjgKiySnFloRSQYKiyQ3oyyfhdOKdN5CRBJKYZECaqoq2bBbLbQikjgKixRQszBooX1GLbQikiAKixRQPTdsod2uoSgRSQyFRQrIycrg/NMrWKdZaEUkQRQWKaKmKsLeoy3sVAutiCSAwiJF1FRVAqgrSkQSQmGRImaW5bOgsoi1unueiCSAwiKF1FRF2PDGEZrVQisiE0xhkUJqqipp7+rmmV2HEl2KiKQZhUUKqZ5bTkFOpqb+EJEJl5XoAiR2uVmZvOv0Cn61sZYDDW2sWTyNv1hUSUVRbqJLE5FJLq5hYWaXAt8FMoGfuPstA9avAm4DlgLXuPv9Ueu6gJfDl2+5+5XxrDVVfOOqJfxo7S4e3XKAx7YewAzOPrWcixdN45LFlcyPFGFmiS5TRCYZi9dFXmaWCWwHLgFqgQ3AR9x9S9Q2c4ES4IvAgwPCosndi2L9vOrqat+4ceP4FJ8C3J0tbzfw2JY6Ht26n1f2NgAwr6KQixdVcvGiaayYU05WpkYaReTkzGyTu1cPt108jyxWAjvd/fWwoHuBq4DesHD33eG67jjWMSmZGUtmlLJkRimfvXgB+4628PhrdTy65QA/fWY3P37qDcoLsrnoHZVcsmgaqxZGKMzVqKOIjE48vz1mAnuiXtcC7xzB/nlmthHoBG5x998O3MDMrgeuBzj11FPHUGrqm1GWz0fPncNHz51DY2sH67cf5LGtB3h8ax2/3ryXnMwMzj99ajhcNY1pJXmJLllEUkg8w2KwgfORjHmd6u77zOw04Akze9ndd/V7M/c7gTshGIYafamTS3FeNlcsnc4VS6fT2dXNht1HeGzrAR7dcoCvbHuFr/z2FZbOKuWSRdO4ePE03nFKsc5ziMiQ4hkWtcDsqNezgH2x7uzu+8Kfr5vZWmA5sGvIneQEWZkZnDd/KufNn8pXrljEzromHglPjt/62Ha+8+h2ZpXn9x5xrJw3hWyd5xCRAeIZFhuABWY2D9gLXANcG8uOZlYOHHf3NjOrAC4AvhW3StOEmbFgWjELphXzqYtOp66xlSe21vHY1gPc8/xb/PSZ3RTnZXFRVSUXL57G6oURSvOzE122iCSBuHVDAZjZ5QStsZnA3e7+TTO7Gdjo7g+a2TnAb4ByoBXY7+5LzOx84A6gm+DCwdvc/a6hPivduqHG2/H2Tp7e0Xee41BzO1kZxrmnTQ26qxZPY1Z5QaLLFJFxFms3VFzDYiIpLMZPV7fz4p4jPLqljke37GdXfTMAi6aXcEkYHGfOLNV5DpFJQGEh4+b1+iYe3xq05W588zDdDqeU5PHuMDjOnz+V3KzMRJcpIqOgsJC4ONzczpOvBec51m2v53h7F4U5maxaGOGSxdO4qKqS8sKcRJcpIjFSWIxEdxdk6DfjkWrt6OLZ1w8FU49sOUBdYxsZFtwzfM3iaVy8aBpzKwoTXaaIDEFhEau2Jvjh+XDGB+G8T0FhxfgXlwa6u51X9h3j0S3B9Ryv7W8EYH6kkLNmlTG/soj5kUJOryzi1CmF5GSpPVckGSgsYtW4H35/I7z6W8jOhxWfgPP/AUqmj3+RaWTP4eM8vvUAT26rZ/uBRt4+1tq7LjPDmDOlgNMiRZwehkgQJkVq1RWZYAqLkarfDk/fCi/dBxlZsPw6eNfnoCy9pxEZL01tnbxR38yu+iZ21jWxqz54vHGwmY6uvr+DkeLcIDwiQXicXlnE/MoippfkkZGh7iuR8aawGK3Db8Afb4MXfgE4LL0GLvw8TJ0/9veWE3R2dbPnSAu7wgDZGfWzobXv9rH52ZmcFg5jRQfJnKkF5GXrfJPIaCksxupYLfzxe7D5Z9DVHpzTuPALULlo/D5DTsrdOdTc3ncUUtd3VLL3aEvvdhkGs6cU9B2FRB2VqCtLZHgKi/HSeACe/T5suAs6mmHR++DCL8KMZeP/WRKTlvYuXj/YcxTSHIZJE68fbKa9s2+2+6mFOUFwVIYBUlnE6ZEiZpbla0hLJKSwGG/HD8NzP4Q/3QFtx2DBGlj1JZi9Mn6fKSPS1e3sPdJywnmRXfXNHG5u790uNyuD0yJRRyFhiJwWKdSQlqQdhUW8tB6D538Mz94OLYdh3qogNOZeCJr+Imkdbm7vPQLpC5Nm9hw5Ts8/ATOYVpzHtNI8TinJZVpJXtQjfF2cR0l+lqY6kUlDYRFvbU2w6afwzPeg6QDMfmcQGqdfrNBIIa0dXbxxsLn3vMhbh49T19jKgYZWDjS0cayl44R98rIzeoNjWmke04rDIIl+XpJHfo6OUiT5KSwmSkcLvPBzePo2aKiF6WcFoVF1BWTowrNU19LeFYZHG/sbWqlrCIJkf0MbB8LX+xtaae048c7AJXlZgx+dRD2PFOfq/iGSUAqLidbZDi/dC0/dCkfegMrFQffUkg9oKpFJzt1paO0MgyQIleggOdDQRl1DK3WNbXR29//3ZgZTC3MHDZLoZVMKcnRSXuJCYZEoXZ3w6q9h/b/AwW0wZX4QGkuvhkxdnZzOuruDduADDa3UNbay/1hb1PMwVBpbOdjUfsK+2ZlGZXEelSW5wfBXSS7TSvOYWZbPrPICZpfnEynO1bkUGTGFRaJ1d8Nr/wnrvw37X4bSU4MrwpdfB1m5ia5Oklh7Zzf1TVHDXMdaOdDYFp5HCULlQEMrjVEXLULQ5TWzPAiPWeX5zA5/zgqXVRTlKEzkBAqLZOEOOx6Bdd+CvRuheDqc/xlY8XHI0Z3nZPSa2zrZe7SF2iPHqT3SQu2RFvYc7nl+nCPH+5+cz8vO6A2SWYOEypRChUk6UlgkG3d4Yx2s+za8+TQUVASz3J7zd5BXkujqZBJqautkb2+A9AVK7dHj7DncckKnV352ZhAeUwYPlLKCbIXJJKSwSGZvPhOc09j1OOSVwjv/O7zzBiiYkujKJI00tHawtydAjgQB0hcqx/vNzQVQmJPZFx6DBEppvsIkFSksUsHeTbD+O7DtIcgphpV/B+d+Cooiia5MhGMtHf2PSMLnPUNdTW39w6Q4N6vfOZP+oVKg6eeTlMIilex/BZ76Drz6G8jKg+qee2rMSHRlIoNydxpaOtkTdSQyMFCa27v67ZOTlUFBTib52Znkhz8LcjLJz8kiPzuDgpws8sJlBTmZvc/7b581YN/gUZCdSZauVxkVhUUq6ndPjcygc+qCz0H5nERXJjIi7s7R4x39AuRgcxst7V20tHdxvKOL1vYujrd30dLRs6yTlvZuWto7Od7RxUi/mrIzrTdYCnKyop6fGDx9z7P6B0923/ZFuVkU5mZRlJtFXnbGpB1iU1ikssNvwB+/G1wZjsPSD8O7Pg8Vpye6MpEJ4e60dXbT2hEEyvH2rt7nQbh00tLzOiqAep73ruvoDNZF7x9u29Ud+3dfhtEbHAU5fUHSs6wwNzN4nhO9LFgeHToFOcF2uVnJEz4Ki8ng2N5g7qlNPw3uqbHkA8EFftOWJLoykZTX3tnde1QThEtnv3Bqbuukua2Tprau8Gfw+nh7V+/zprZOmts7aW4LlkVPkT+UrAw7MWhysyjsDZvMfmF0soDqWTaWKWMUFpNJU13fPTXam2DmCsgtDs5vZOYEP7Nyw8dgy3IhM7f/Nics69k36nVGliZFFBmBjq7uqGDpC5XosGkeGDYDto0Oo4HTw5zM2aeW8ev/ccGoao41LLJG9e4ysYoq4ZKbg/MXf/pR0Hrbfjy4x0ZXO3S2Qmdb36OrDbr5ztlkAAAKiklEQVQ7h3/f4VjGgPDJGRA0gy0bGEp5UDoLppwWTH1SMEUBJJNWdmYGZQU5lBWM/S6NPUNx/cKkvXNAAAVHPVOL4n9XSIVFKimYAhf9U2zbdnUGoREdIJ1tYbCEARO9vmddb/j0/BxsWdT7tTZAZ/3J348BvxnllsKUeWF4nBbc27zneWFEQSISMjPysoOT7VOLEl2NwmLyyswKHjmFiavBPQiNY3vg0C44/HrfY99m2PJb8Kgx3pyiMEiiAqQnUIqmKUhEEkhhIfFjBtl5ULEgeAzU2R4ESU+A9ATK/pfhtf/qP5SWXRCGx7y+Ia2eMCmernuHiMSZwkISJysnOGqYOv/EdV2dYZDsClqJewKl7jXY9nvojprXKCs/KkSihrimzIeSmQoSkXGgsJDklJkVfvHPO3Fddxccq+0/rHX4dTi0E3Y8Gpw76X2fXCifGzWkFTW8VTpbN6aSYLi05Qg07AsejfugqR6y84O52/JKIb+s73leKeSWpN3fHYWFpJ6MzOCq9vI5MP+i/uu6u4N/7APPkRx+A15fC50tUe+THbxHvyGtU8LOrpyoDq+cAT+j1qu9OLl1dUJzXV8Q9IRBwz5oeBsa9kLj22EzxgjlloThMSBIThYwvY+y4Pxcih3xKixkcsnICFp1S2fBaav7r+vuhqb9J54jOfwG7H4aOppH8YE2RKgMEi4n/Ix1+5Nsl1MUXHOTnZ9+odXREhUA4Rd/dAA0vB38//YBF8pl5gTzrhXPCK5ZKpkeDFcWTw+Wl8yAwsrgF4vWY/0fLUdPXNbzOPpm3/O2hqFrt4yosBkYLgNDZpDQySmc8P/fCgtJHxkZfV8Gc9/Vf517cPFj04GwVbinPbh9wM+2qPXt/Z/3+zlg346jJ3+Pzrb+52BGwzIhtyiYvTi35xEGSc6A14MtyykKvrxyi4JrYxIZPO7QevTE3/57wyA8Omg5cuK+uaXhl/8MiCwK/39Hh8HM2K/1ycoJvphHo7srCIwhA2bA8kO7+rYf7heXjKz+4TF9GbzvttHVGiOFhQgEXx7F04JHInR3h+EzRDANFkLtTdDWGDyin7c1BtfANOwLXzeFv+3GcEVwRtYQgVLcFyr9lhUPvs3AWwh3dwWh3G84qOfIIOp19HAhABZch1MyIxg6nHNe35d/dBjkJsEFCRAMleaXB4/yUezf1RH8/+sXKCcJnZajE3L+RGEhkgwyMiAjL2g1jhd36DjeP1AGC5nBlrUcgaNv9QVPe2Nsn5mZ0xcg3Z3QuB+8/9TlZGT3feFPPwuqLus7Aizu+XkKZKbR/TAys6FwavBIEgoLkXRhFox15xQGX75j0d0dDJX0HrU0BkcuvSHTNOB1Y3DEEn1eoCcMCqam3MnedKSwEJGRy8joG3qStKA4FxGRYcU1LMzsUjPbZmY7zezGQdavMrPNZtZpZh8asO5jZrYjfHwsnnWKiMjQ4hYWZpYJ3A5cBiwGPmJmiwds9hbwceCXA/adAnwdeCewEvi6mY2mp0BERMZBPI8sVgI73f11d28H7gWuit7A3Xe7+0vAwNtLvQd41N0Pu/sR4FHg0jjWKiIiQ4hnWMwE9kS9rg2Xjdu+Zna9mW00s4319fWjLlRERIYWz7AY7BLJWO/hGtO+7n6nu1e7e3UkEhlRcSIiErt4hkUtMDvq9Sxg3wTsKyIi4yyeYbEBWGBm88wsB7gGeDDGff8ArDGz8vDE9ppwmYiIJIC5xzoyNIo3N7scuA3IBO5292+a2c3ARnd/0MzOAX5DMHtKK7Df3ZeE+/4N0HPD6W+6+78N81n1wJtjKLcCODiG/SdSKtUKqVVvKtUKqVVvKtUKqVXvWGqd4+7DjuPHNSxSiZltdPfqRNcRi1SqFVKr3lSqFVKr3lSqFVKr3omoVVdwi4jIsBQWIiIyLIVFnzsTXcAIpFKtkFr1plKtkFr1plKtkFr1xr1WnbMQEZFh6chCRESGpbAQEZFhpX1YDDeNejIxs7vNrM7MXkl0LcMxs9lm9qSZbTWzV83ss4muaShmlmdmz5vZn8N6v5HomoZjZplm9oKZ/VeiaxmOme02s5fN7EUz25joeoZiZmVmdr+ZvRb+/T0v0TWdjJlVhf9Nex4NZva5uHxWOp+zCKdR3w5cQjDFyAbgI+6+JaGFnYSZrQKagH939zMSXc9QzGw6MN3dN5tZMbAJeH8S/7c1oNDdm8wsG3ga+Ky7P5fg0k7KzD4PVAMl7v7eRNczFDPbDVS7e9Jf5GZmPwOecvefhLNPFLj70UTXNZzw+2wv8E53H8sFyoNK9yOLYadRTybuvh44nOg6YuHub7v75vB5I7CV2GcdnnAeaApfZoePpP1NysxmAVcAP0l0LZOJmZUAq4C7ANy9PRWCIvRuYFc8ggIUFmOZRl1iZGZzgeXAnxJbydDCYZ0XgTqC+6kkc723Af/IifeCSVYOPGJmm8zs+kQXM4TTgHrg38Ihvp+YWWGii4rRNcA98XrzdA+LsUyjLjEwsyLgAeBz7t6Q6HqG4u5d7r6MYJbjlWaWlEN9ZvZeoM7dNyW6lhG4wN3PJrhz5qfCIdVklAWcDfzQ3ZcDzUBSn8sECIfLrgR+Fa/PSPew0FTocRSO/T8A/MLdf53oemIVDjusJXnvzngBcGV4HuBe4C/M7OeJLWlo7r4v/FlHMHnoysRWdFK1QG3UUeX9BOGR7C4DNrv7gXh9QLqHxVimUZchhCeM7wK2uvutia5nOGYWMbOy8Hk+cDHwWmKrGpy73+Tus9x9LsHf2Sfc/boEl3VSZlYYNjkQDumsAZKyo8/d9wN7zKwqXPRuICmbMgb4CHEcgoLgkCttuXunmX2a4F4ZPdOov5rgsk7KzO4BaoAKM6sFvu7udyW2qpO6APgo8HJ4HgDgn9z94QTWNJTpwM/CjpIM4D53T/qW1BQxDfhN8PsDWcAv3f33iS1pSP8A/CL8BfJ14BMJrmdIZlZA0NF5Q1w/J51bZ0VEJDbpPgwlIiIxUFiIiMiwFBYiIjIshYWIiAxLYSEiIsNSWIgkATOrSYXZYyV9KSxERGRYCguRETCz68L7XrxoZneEkw82mdl3zGyzmT1uZpFw22Vm9pyZvWRmvzGz8nD56Wb2WHjvjM1mNj98+6Ko+yj8IrwKXiQpKCxEYmRmi4APE0yKtwzoAv4aKCSYl+dsYB3w9XCXfwe+7O5LgZejlv8CuN3dzwLOB94Oly8HPgcsJpj99IK4/6FEYpTW032IjNC7gRXAhvCX/nyC6cy7gf8It/k58GszKwXK3H1duPxnwK/COZJmuvtvANy9FSB8v+fdvTZ8/SIwl+AmTCIJp7AQiZ0BP3P3m/otNPvqgO2GmkNnqKGltqjnXejfpyQRDUOJxO5x4ENmVglgZlPMbA7Bv6MPhdtcCzzt7seAI2Z2Ybj8o8C68J4etWb2/vA9csOJ4ESSmn5zEYmRu28xs68Q3PEtA+gAPkVwg5wlZrYJOEZwXgPgY8CPwjCInr30o8AdZnZz+B5/NYF/DJFR0ayzImNkZk3uXpToOkTiScNQIiIyLB1ZiIjIsHRkISIiw1JYiIjIsBQWIiIyLIWFiIgMS2EhIiLD+v8axqR2YHGWpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
